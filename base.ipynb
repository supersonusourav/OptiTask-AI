{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fdc840e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.7)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: pulp in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.0)\n",
      "Collecting langchain-groq\n",
      "  Downloading langchain_groq-1.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-openai) (2.16.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core) (0.6.4)\n",
      "Requirement already satisfied: packaging>=23.2.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.13.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2026.1.15)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sures\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.3)\n",
      "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
      "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sures\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sures\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sures\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
      "Downloading langchain_groq-1.1.2-py3-none-any.whl (19 kB)\n",
      "Downloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
      "Installing collected packages: groq, langchain-groq\n",
      "\n",
      "  Attempting uninstall: groq\n",
      "\n",
      "    Found existing installation: groq 1.0.0\n",
      "\n",
      "    Uninstalling groq-1.0.0:\n",
      "\n",
      "      Successfully uninstalled groq-1.0.0\n",
      "\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   -------------------- ------------------- 1/2 [langchain-groq]\n",
      "   ---------------------------------------- 2/2 [langchain-groq]\n",
      "\n",
      "Successfully installed groq-0.37.1 langchain-groq-1.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-openai langchain-core pulp pandas langchain-groq pulp pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3165d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Error: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\n"
     ]
    }
   ],
   "source": [
    "import pulp\n",
    "import pandas as pd\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Get your free key at https://console.groq.com/\n",
    "os.environ[\"GROQ_API_KEY\"] = \"gsk_your_key_here\"\n",
    "\n",
    "# --- 2. DATA ENGINEERING ---\n",
    "data = {\n",
    "    \"Consultant\": [\"Arjun\", \"Sara\", \"Chen\", \"Elena\"],\n",
    "    \"Skill\": [\"NLP\", \"Azure Cloud\", \"Optimization\", \"NLP\"],\n",
    "    \"Hourly_Rate\": [150, 120, 200, 140],\n",
    "    \"Availability_Hours\": [40, 20, 30, 40]\n",
    "}\n",
    "df_resources = pd.DataFrame(data)\n",
    "\n",
    "# --- 3. GEN-AI LAYER (Using Llama 3 via Groq) ---\n",
    "class ProjectNeeds(BaseModel):\n",
    "    required_skill: str = Field(description=\"The technical skill required\")\n",
    "    estimated_hours: int = Field(description=\"The hours the task will take\")\n",
    "\n",
    "def run_ai_pipeline(user_query):\n",
    "    try:\n",
    "        # EY JD mentions \"Hugging Face\" and \"LLMs\" - Llama 3 is the top choice here\n",
    "        llm = ChatGroq(\n",
    "            model_name=\"llama3-70b-8192\",\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        parser = JsonOutputParser(pydantic_object=ProjectNeeds)\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"You are an EY Resource Manager. Analyze this project request: {query}\\n\\n{format_instructions}\"\n",
    "        )\n",
    "        \n",
    "        chain = prompt | llm | parser\n",
    "        return chain.invoke({\n",
    "            \"query\": user_query,\n",
    "            \"format_instructions\": parser.get_format_instructions()\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"AI Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 4. OPTIMIZATION LAYER (MIP) ---\n",
    "def solve_allocation(extracted_data):\n",
    "    if not extracted_data: return \"No data to optimize.\"\n",
    "    \n",
    "    skill = extracted_data['required_skill']\n",
    "    hours = extracted_data['estimated_hours']\n",
    "    \n",
    "    # Filtering\n",
    "    mask = (df_resources['Skill'] == skill) & (df_resources['Availability_Hours'] >= hours)\n",
    "    qualified = df_resources[mask].copy()\n",
    "    \n",
    "    if qualified.empty:\n",
    "        return f\"No consultant available for {skill} for {hours} hours.\"\n",
    "\n",
    "    # Solve\n",
    "    prob = pulp.LpProblem(\"Resource_Optimization\", pulp.LpMinimize)\n",
    "    names = qualified['Consultant'].tolist()\n",
    "    x = pulp.LpVariable.dicts(\"assign\", names, cat=pulp.LpBinary)\n",
    "    \n",
    "    prob += pulp.lpSum([x[n] * qualified.loc[qualified['Consultant'] == n, 'Hourly_Rate'].values[0] * hours for n in names])\n",
    "    prob += pulp.lpSum([x[n] for n in names]) == 1\n",
    "    \n",
    "    prob.solve(pulp.PULP_CBC_CMD(msg=0))\n",
    "    \n",
    "    for n in names:\n",
    "        if pulp.value(x[n]) == 1:\n",
    "            return {\"Consultant\": n, \"Total_Cost\": f\"${pulp.value(prob.objective)}\", \"Status\": \"Optimal\"}\n",
    "\n",
    "# --- 5. EXECUTION ---\n",
    "query = \"We need a consultant for an NLP project. It should take about 25 hours.\"\n",
    "needs = run_ai_pipeline(query)\n",
    "\n",
    "if needs:\n",
    "    print(\"--- AI Extracted Needs ---\")\n",
    "    print(needs)\n",
    "    result = solve_allocation(needs)\n",
    "    print(\"\\n--- Optimized Assignment ---\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62392340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ey_resource_pool.csv with 2000 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# EY JD Requirement: Data Engineering - Curating and preprocessing datasets\n",
    "def generate_big_dataset(rows=100):\n",
    "    skills = [\"NLP\", \"Azure Cloud\", \"Optimization\", \"Computer Vision\", \"Data Engineering\", \"MLOps\"]\n",
    "    names = [f\"Consultant_{i}\" for i in range(rows)]\n",
    "    \n",
    "    data = {\n",
    "        \"Consultant\": names,\n",
    "        \"Skill\": [random.choice(skills) for _ in range(rows)],\n",
    "        \"Hourly_Rate\": [random.randint(80, 250) for _ in range(rows)],\n",
    "        \"Availability_Hours\": [random.randint(5, 45) for _ in range(rows)]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"ey_resource_pool.csv\", index=False)\n",
    "    print(f\"Created ey_resource_pool.csv with {rows} rows.\")\n",
    "\n",
    "generate_big_dataset(2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
